# Выявление токсичных комментариев

[ipynb](https://github.com/mvs834/Yandex.Practicum-RUS/blob/346d5c78d45f2053aea598555d54ae9550e64705/Car%20Price%20Prediction/Car_Price_Prediction.ipynb)

## Описание проекта

Необходимо искать токсичные комментарии на основе набора данных с разметкой токсичности.

## Навыки и инструменты

- **python**
- **pandas**
- **numpy**
- matplotlib.**pyplot**
- **seaborn**
- sklearn.preprocessing.**StandardScaler**
- sklearn.preprocessing.**OrdinalEncoder**
- sklearn.**pipeline**
- sklearn.linear_model.**LinearRegression**
- sklearn.tree.**DecisionTreeRegressor**
- sklearn.ensemble.**RandomForestRegressor**
- **lightgbm**
- **xgboost**
- catboost.**CatBoostRegressor**

## Ход выполнения проекта
### Подготовка данных
- данные представлены в виде текстовых комментариев
- пропусков и дубликатов нет
- целевой признак несбалансирован

### Очистка и лемматизация текста
- очистка текста от знаков препинания, цифр, символов и пр. кроме букв и приведение к строчным буквам
- лемматизация текста двумя способами NLTK (более быстрый) и Spacy (более долгий)

### Обучение моделей
- векторизация текста методом TF-IDF
- обучение моделей логистической регрессии, дерева решений, случайного леса, градиентного бустинга и катбуста
- наилучший результат показала модель логистической регрессии

### Оценка лемматизации
- лемматизация текста с помощью Spacy показала лучший результат

### Тестирование
- модель логистической регрессии показала наилучший результат с данными, леммаизированными с помощью Spacy

## Вывод

Текст загружен, в предобработке не нуждался. Подготовка данных заключалась в очистке от знаков препнания, цифр, символов и пр. кроме букв и приведении к строчным буквам. Лемматизация проводилась двумя способами NLTK (более быстрый) и Spacy (более долгий). Для обучения текстовые данные векторизовались методом TF-IDF. Обучение происходило посредством логистической регрессии и деревянных моделей. Логистическая регрессия показала наилучший результат. Лемматизация оказалась лучше методом Spacy.

В качестве дальнейших шагов по улучшению метрики можно выполнить токенизацию, обучение с градиентным бустингом и векторизацию нейронной сеткой BERT.
